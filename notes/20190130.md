# Porting Tunnel

Alright, time for a demo with some real meat to it.

First, this one requires the direct-color rasterizer. I'm going to see if I
can't eliminate its code, replacing it with `memcpy` or equivalent.

First crack: using `slice::copy_from_slice` in a pixel-doubled context, so
moving 400 bytes. It compiles down to good ol' `__aeabi_memcpy`... which is
about the worst copy code I've ever seen. I wonder where this code came from?

Anyhoo. Here's the code.

```rust
|ln, tgt, ctx| {
    let coarse_ln = ln / SCALE;
    if coarse_ln < HALF_HEIGHT {
        let offset = coarse_ln * BUFFER_STRIDE;
        let buf = fg.try_lock().expect("rast fg access");
        // TODO: this is *ridiculously* slow.
        tgt[.. WIDTH].copy_from_slice(
            // u32_as_u8 is fn(&[u32]) -> &[u8]
            u32_as_u8(&buf[offset .. offset + BUFFER_STRIDE])
        );
        ctx.target_range = 0..WIDTH;
        ctx.cycles_per_pixel *= 2;
        ctx.repeat_lines = 1;
    } else {
        // lol whatever bottom half
    }
},
```

The rasterizer using `copy_from_slice` takes 15.57us to run. That's less than a
scanline, so it's actually not implausible.

---

I've jumped through some hoops to ensure that target buffers are always 32-bit
aligned. Using `copy_from_slice` on `[u32]` instead gets us down to 5.7us by
using `__aeabi_memcpy4`, which assumes alignment. (Why `__aeabi_memcpy` doesn't
transfer 0-3 bytes and then call `__aeabi_memcpy4` is beyond me.)

And of course there's `copy_words`. It works the first time, with no mysterious
crashing or corrupted display... memory safe languages are a really pleasant
place to work.

Anyway. `copy_words` takes 2.572us. Yup, twice as fast as `memcpy4` and a cool
six times faster than the original implementation. That's why I keep it around.
Not only does rasterization finish within hblank, it finishes *within the hsync
pulse*.

Which is important, because this is the raster mode that I use for my most
compute-intensive demos. Like this one I'm porting!

```rust
|ln, tgt, ctx| {
    if coarse_ln < HALF_HEIGHT {
        let offset = coarse_ln * BUFFER_STRIDE;
        let buf = fg.try_lock().expect("rast fg access");
        m4vga::util::copy_words::copy_words(
            &buf[offset .. offset + BUFFER_STRIDE],
            &mut tgt.as_words_mut()[..BUFFER_STRIDE],
        );
        ctx.target_range = 0..WIDTH;
        ctx.cycles_per_pixel *= 2;
        ctx.repeat_lines = 1;
    } else {
        // lol whatever bottom half
    }
},
```

---

The bottom half of the screen is a trick, in case you haven't read the code. It
uses the same framebuffer as the top half, but rotated 180 degrees -- that is,
flipped horizontally and vertically. This is the sort of weirdness that I can
indulge in a software rasterizer.

Flipping the bottom half vertically is really easy: just change the addresses we
use at each scanline to work bottom-to-top:

```rust
|ln, tgt, ctx| {
    let coarse_ln = ln / SCALE;
    let coarse_ln = if coarse_ln < HALF_HEIGHT {
        coarse_ln
    } else {
        // flip bottom half of screen vertically
        HEIGHT - coarse_ln - 1
    };
    let offset = coarse_ln * BUFFER_STRIDE;
    let buf = fg.try_lock().expect("rast fg access");
    m4vga::util::copy_words::copy_words(
        &buf[offset .. offset + BUFFER_STRIDE],
        &mut tgt.as_words_mut()[..BUFFER_STRIDE],
    );
    ctx.target_range = 0..WIDTH;
    ctx.cycles_per_pixel *= 2;
    ctx.repeat_lines = 1;
},
```

Flipping horizontally is harder. The DMA controller that we use for scanout
can't count backwards (shame, that). So we need to reverse the order of the
pixels during the raster callback.

First crack: the naive way.

```rust
let tgt = tgt.as_words_mut()[..BUFFER_STRIDE].iter_mut();
let src_rev = buf[offset .. offset + BUFFER_STRIDE].iter()
    .rev();
for (dst, src) in tgt.zip(src_rev) {
    *dst = src.swap_bytes()
}
```

That takes 5.744us per scanline, finishing *just after* SAV. Reviewing the
disassembly, this is going to be *much faster* than the handwritten routine I
used in C++...because LLVM has inlined it what appears to be 25x. Well then. I
guess I didn't set `-Oz`, did I.

Done. Moving on. If the binary's too large I can change this later.

---

I initially declared my two framebuffers as undecorated statics, like so:

```rust
static mut BUF0: [u32; BUFFER_WORDS] = [0; BUFFER_WORDS];
static mut BUF1: [u32; BUFFER_WORDS] = [0; BUFFER_WORDS];
```

Because of how my linker script is set up, this puts them both in SRAM1, which
is AHB-attached. This seems to mess up DMA timing on the bottom half of the
screen, because it's slightly fuzzy -- if I move the buffer into CCM (and only
use one) we're good.

Ah. The latency-sensitive ISRs were in Flash. This can cause unpredictable
interrupt latency. It's not immediately obvious to me why generating SRAM1 AHB
traffic would affect that, but I'll worry about it later.

---

Of course both those buffers won't fit in a single SRAM. Gotta move one into CCM
anyway. With that, I can turn on buffer flipping with this main loop:

```rust

let fg = SpinLock::new(unsafe { &mut BUF0 });
let mut bg = unsafe { &mut BUF1 };

// ... things happen ...

|vga| {
    vga.video_on();
    loop {
        vga.sync_to_vblank();
        core::mem::swap(&mut bg,
                        &mut *fg.try_lock().expect("swap access"));
    }
}
```

There. Double-buffered.

At this point we've got the display mode we need for Tunnel.

---

Drawing circles usually wants trig. Trig is usually slow. Demos in the "tunnel
zoomer" class circumvent this by precomputing a lookup table; this demo is no
different.

There is a lookup table describing one quarter of the screen; as it's radially
symmetric, you don't need more than one quarter. Since our screen is already
using 2x2 "fat pixels," we need a 200x150 table.

Each table entry contains two values: the distance from the center to the point,
and the angle from the Y axis. This means we'd need 200x150x4x2=240 kilobytes to
store the table using `f32`. We technically have enough Flash to pull this off
if we precomputed it at compile time -- and, in fact, the C++ demo leaves the
table in Flash, because the access patterns tend to hit the cache.

The C++ demo makes the table smaller using two techniques. First, the table is
subsampled 4x in each direction, 16x total, giving us a 50x38 table. Then, each
entry is represented using half-precision floating point. This gets the
footprint down to 50x38x2x2=7600 bytes. That's much more palatable.

Finally, the C++ demo precomputes the tables at compile time using constexpr and
templates.

Rust doesn't have `f16` support, so I'm going to skip that last step and
tolerate the 2x growth it implies. Rust also can't reasonably compute a trig
table at compile time (short of using a build script) so I'll start by computing
it at runtime. If I'm going to compute it at runtime, it'll need to be in RAM,
not Flash -- but at something like 14kiB I can easily afford that, as long as I
place it in SRAM1 with the rest of BSS.

---

So, discovery #1 when attempting to compute a lookup table: `core` doesn't have
trig, or any math support really. That's frustrating.

I'm going to pull in the `libm` crate for starters and evaluate its performance.

Of course, to do that, I need to get rustc to actually include the code in the
output... it's smart enough that I *really do need to be using it* for that to
happen.

Anyway, the answer is that the performance is *atrocious*. `sin` is using what
I'm guessing is a Taylor-series expansion that will take hundreds of cycles;
remember that this CPU has a `vsqrt` instruction that takes 14 cycles,
pipelined.

But! I'm deliberately moving the trig out of the critical path by doing this
lookup table. So who cares!

---

I've glossed the C++ rendering code into Rust, which only required a few
changes, all because of mixed `u32`/`f32` arithmetic.

The shading method produces *different results* in Rust. Given my shading
algorithm this is no surprise...I'm doing bit manipulation and shifts, which we
know have different corner case behavior in Rust.

The rest of the rendering code looks great. It's leaving four pixels of garbage
at the top and bottom of the display -- I don't remember if C++ does the same
thing. (It's because the display is taller than an even multiple of the
subdivided block size, by a fraction of a block.)

The rendering code takes 9.549ms, or 57% of the frame, to complete. I don't
remember how long it took in C++, but I feel like it was longer than that, which
was why I did all those crazy optimizations. I mean, the C++ code sports this,
for chrissakes:

    __attribute__((optimize("prefetch-loop-arrays")))

...I remembered correctly. The C++ demo *runs at 30fps.* The render routine --
the same one I just glossed into Rust, but without bounds checks -- takes
20.71ms, or about a frame and a half. And that's using GCC 8.2.0 at `-O2`, not
my original 4.9-based toolchain.

So the Rust one is just about twice as fast. That's surprising, since the code
is so similar. But here I am, watching this do 60fps.

---

I'm starting to remember more. For example, why is tunnel not implemented as a
rasterizer? Why does it bother having a framebuffer? *Because it didn't use to
be fast enough.*

Instrumentation time.

An entire macro-row pass takes 263.9us, or about 10 scanlines. Each such pass
generates 16 scanlines' worth of output. But it's getting to cheat because of
mirroring: without mirroring it only produces 8 scanlines and then has to
recompute the other 8 later. That's not quiiiite fast enough to run realtime.

Close enough that it might be interesting to play with, though.

---

If I force `render` not to inline, it's up to 10.29us, or almost exactly half.

Okay, I've found the culprit: despite writing little static functions that get
called once, or nearly trivial accessors that are in header files, GCC wasn't
inlining *anything.* I've beaten a half dozen functions with the always-inline
stick, and now the C++ code performs very close to the Rust. (At 9.8us, it's
slightly faster -- which makes sense, as it's able to use half-precision floats
to reduce memory traffic.)

It seems only fair to push that fix to the C++ repo.




